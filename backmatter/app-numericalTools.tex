\chapter{Numerical Tools}

\section{Numerical Computation of the Scattering Matrix}\label{sec:app.numTools.scatMat}
In the TE case, we must take $n\mapsto n_\text{eff}$. This leads us to evaluate the 
extra integral
  \begin{equation}
   I = \frac{1}{2\pi}\int_0^{2\pi}\left[\frac{1}{n}\frac{d^2n(r_j,\theta)}{d\theta^2}-\frac{2}{n^2}\left(\frac{dn(r_j,\theta)}{d\theta}\right)^2\right]e^{i(m-m')\theta}d\theta.
  \end{equation}
The numerical cost of this integral can be lessened 
if we notice that if we write it as a function of $n^2$ we obtain
  \begin{equation}
   I = \frac{1}{2\pi}\int_0^{2\pi}\left[\frac{1}{2n^2}\frac{d^2n^2(r_j,\theta)}{d\theta^2}-\frac{3}{4n^4}\left(\frac{dn^2(r_j,\theta)}{d\theta}\right)^2\right]e^{i(m-m')\theta}d\theta
  \end{equation}
which, in turn, can be rewritten as
  \begin{equation}
   I = \frac{1}{2\pi}\int_0^{2\pi}\left[\frac{1}{2}\frac{d^2\log n^2(r_j,\theta)}{d\theta^2}-\left(\frac{1}{2}\frac{d\log n^2(r_j,\theta)}{d\theta}\right)^2\right]e^{i(m-m')\theta}d\theta.
  \end{equation}
Integrating by parts twice yields
  \begin{equation}
   I = \frac{1}{2\pi}\int_0^{2\pi}\left[-\frac{(m-m')^2}{2}\log n^2(r_j,\theta)-\left(\frac{1}{2}\frac{d\log n^2(r_j,\theta)}{d\theta}\right)^2\right]e^{i(m-m')\theta}d\theta.
  \end{equation}
The second term cannot be integrated out, but this final result means that
we will only need to numerically evaluate the first derivative of the 
refractive index (although its analytical form could be provided).

Notice the form of the $\mat{L}^j$ matrix. As can be seem from inspection, 
the value of the elements depend only on their distance from the diagonal.
Taking a closer look reveals the form
  \begin{equation}
   \mat{L}^j = \mat{M}^2 +\begin{pmatrix} 
		  n_0 & n_{-1} & \cdots & \cdots & n_{-2M}	\\
		  n_1	  & n_0& \cdots & \cdots & n_{-2M-1}\\
		  n_2	  & n_1	   & n_0& \cdots & n_{-2M-2}\\
		  \vdots  & n_2    & n_1    & \ddots & \vdots   \\
		  n_{2M}  & \cdots & \cdots & \cdots & n_0
		\end{pmatrix}
  \end{equation}
which is manifestly Toeplitz. When the potential is real, the Fourier
series has the property $n_{-j}=n_j^*$, which makes the $\mat{L}^j$ 
matrix Hermitian. In the general case, however, it is not. Because
we will need to use orthogonality relations in what follows, we must
compute both the left and right eigenvectors\index{left eigenvectors}. 
We will note the left (covariant) basis by $\Ket{\tilde{\Phi}_\mu^j}$.
This is not sufficient, however, because we are not guaranteed that
both sets of eigenvectors will form a complete basis. 

\section{Computation of the Logarithmic Derivative $[H^{(\pm)}_\nu(z)]'/H^{(\pm)}_\nu(z)$}\label{sec:app.numTools.logDeriv}

\index{continued fraction expansions|(textbf}
As we have seen from Appendix \ref{app:basicEquations}, the computation of the logarithmic derivative
of Bessel functions is of the upmost importance in the numerical solution 
of scattering problems. Given that we already use Amos' library to evaluate
the Bessel functions, we might have been tempted to use it 
to directly evaluate the derivative. It turns out that using
expansions that pertain to logarithmic derivatives is somewhat
faster and is more accurate than using Amos' library. 

In this section, we introduce some concepts relating to 
continued fraction expansions (CFEs) and discuss their numerical
evaluation. We then derive the CFEs and other expansions that will
be of use in the computation of the logarithmic derivatives.

\subsection{Notation and Necessary Theorems}
A continued fraction expansion is a representation
of a mathemetical function. It can be linked to 
Laurent series, Padé approximants and much more 
\cite{CUY2008}. It has the standard form 
  \begin{equation}
    f = b_0+\cfrac{a_1}{b_1+\cfrac{a_2}{b_2+\cfrac{a_3}{b_3+\cfrac{a_4}{b_4+\cdots}}}}
  \end{equation}
or, more succinctly, 
  \begin{equation}
   f = b_0 + \bigk_{m=1}^\infty\left(\frac{a_m}{b_m}\right)
  \end{equation}
where 'K' is for the German word \textit{Kettenbruch}, meaning continued fraction.
We define the $n$th approximant as
  \begin{equation}
   f_n = b_0 + \bigk_{m=1}^n\left(\frac{a_m}{b_m}\right).
  \end{equation}
We will be concerned with their numerical evaluation and convergence properties.

\index{continued fraction expansions!numerical evaluation of}
Notice that naïvely evaluating the CFE from right-to-left, as a person would do, 
does not yield a satisfying numerical algorithm, as the amount of iterations 
must be fixed in advance and consequently does not allow the control the 
accuracy of the evaluation. The chosen method is taken from the Holy Bible
of Numerics, \textit{Numerical Recipes} \cite{PRE2007} and is called 
the modified Lentz's method. It constructs a rational approximation
of the $n$th approximant 
  \begin{equation}
    f_n = \frac{A_n}{B_n}
  \end{equation}
where 
  \begin{align}
   A_{-1} 	&=1 			& B_{-1} 	&=0	\nonumber\\
   A_0		&= b_0			& B_0		&=1	\\
   A_j		&=b_jA_{j-1}+a_jA_{j-2}	& B_j 		&=b_jB_{j-1}+a_jB_{j-2}.\nonumber
  \end{align}
This method can lead to over/underflow of the floating-point representation: 
the method hence uses 
  \begin{align}
    C_j &= A_j/A_{j-1}			&	D_j	&= B_{j-1}/B_j	\nonumber\\
    	&= b_j+\frac{a_j}{C_{j-1}}	&		&= \frac{1}{b_j+a_jD_{j-1}}\\
    f_j	&= f_{j-1}C_jD_j.\nonumber
  \end{align}
The method is aptly described by Algorithm \ref{algo:app.numTools.cfeEvaluation}.
It allows for a left-to-right evaluation of the CFE and control of the relative
accuracy of the computation. 

  \begin{algorithm}
   \KwData{\texttt{tiny} = square root of smallest representable number}
   \KwData{\texttt{eps} = accuracy of the CFE}
   \eIf{$b_0 = 0$}{$f_0\leftarrow$\texttt{tiny}}{$f_0\leftarrow0$}
   $C_0 \leftarrow f_0$\;
   $D_0 \leftarrow 0$\;
   \Repeat( from $j=1$){$|\Delta_j-1|<$\texttt{eps}}%
   {
    $D_j \leftarrow b_j+a_jD_{j-1}$\;
    \If{$D_j=0$}{$D_j\leftarrow$\texttt{tiny}}
    $C_j \leftarrow b_j+\frac{a_j}{C_{j-1}}$\;
    \If{$C_j=0$}{$C_j\leftarrow$\texttt{tiny}}
    $D_j \leftarrow 1/D_j$\;
    $\Delta_j\leftarrow C_jD_j$\;
    $f_j \leftarrow f_{j-1}\Delta_j$
   }
   \Return{$f_j$}
  \caption{Evaluation of Continued Fractions}
  \label{algo:app.numTools.cfeEvaluation}
  \end{algorithm}

As for the convergence properties, we will only bother with CFEs 
originating from three-term recurrence relations. Indeed, it turns out
that any three-term recurrence relation can be linked to a CFE. 
Consider  
  \begin{equation}
    \label{eq:app.numTools.threeTermRecurrence}
   y_{n+1} + a_ny_n + b_ny_{n-1} = 0. 
  \end{equation}
It can be rewritten as
  \begin{equation}
    \frac{y_n}{y_{n-1}} = -\frac{b_n}{a_n+y_{n+1}/y_n}.
  \end{equation}
Iterating yields the CFE
  \begin{equation}
   \label{eq:app.numTools.recurrenceCFE}
   \frac{y_n}{y_{n-1}} = \bigk_{m=n}^\infty\left(\frac{-b_m}{a_m}\right).
  \end{equation}
Given our goal of computing $[H^{(\pm)}_\nu(z)]'/H^{(\pm)}_\nu(z)$
and in light of (ref to recurrence relation of Bessel functions), it seems that
we have won. The next theorem, however, will prove us wrong.
   \begin{thm}[Pincherle's Theorem \cite{CUY2008}]
    If there exists a \textit{minimal solution} $u_n$ of the three-term
    recurrence relation \eqref{eq:app.numTools.threeTermRecurrence}, 
    the associated CFE \eqref{eq:app.numTools.recurrenceCFE} converges
    to $u_n/u_{n-1}$. A solution is said minimal if there exists another
    solution $v_n$ such that
      \begin{equation}
       \lim_{n\rightarrow\infty} \frac{u_n}{v_n} = 0.
      \end{equation}
    $v_n$ is said to be the dominant solution. The minimal solution is unique. 
   \end{thm}

Because the minimal solution of \eqref{eq:app.Bessel.recurrenceBessel} if $J_\nu(z)$, 
we cannot use the associated CFE to compute the logarithmic derivatives
of Hankel functions. Instead, we must look into the links between
Hankel functions and confluent hypergeometric functions. 

\subsection{CFE and Other Expansions}
In this brief foray into the vast subject
of hypergeometric functions, we will introduce Kummer's 
function and its link to the evaluation of the logarithmic
derivative.

Kummer's function solves the differential equation \cite[\S13.1.1]{ABR1965}
  \begin{equation}
    z\frac{d^2y}{dz^2}+(b-z)\frac{dy}{dz}-ay=0
  \end{equation}
and is noted $U(a,b,z)$. It can be shown that that $u_k=(a)_kU(a+k,b,z)$
is the minimal solution of the recurrence \cite{TEM1983}
  \begin{equation}
    u_{n+1} = \frac{2a-b+2n+z}{a-b+n+1}u_n - \frac{a+n-1}{a-b+n+1}u_{n-1}
  \end{equation}
where $(a)_k$ is the Pochhammer symbol. We can hence derive
  \begin{equation}
    \frac{U(a,b,z)}{U(a+1,b,z)} = 2a-b+2+z-\bigk_{m=1}^\infty\left(\frac{(a+m)(b-a-m-1)}{b-2a-2m-2-z}\right).
  \end{equation}
Combined with \cite[\S13.4.23]{ABR1965}
  \begin{equation}
    U(a+1,b,z) = \frac{1}{1+a-b}U(a,b,z) + \frac{z}{a(1+a-b)}U'(a,b,z), 
  \end{equation}
we obtain \cite{CUY2008}
  \begin{equation}
    \frac{dU(a,b,z)/dz}{U(a,b,z)} = -\frac{a}{z}+\frac{a(1+a-b)/z}{2a-b+2+z}_{-}\bigk_{m=1}^\infty\left(\frac{(a+m)(b-a-m-1)}{b-2a-2m-2-z}\right).
  \end{equation}
Given the relation between Kummer's functions and Hankel functions $H^\omega_{\nu}(z)$ \cite[\S13.6.22/23]{ABR1965}
  \begin{equation}
    H^\omega_\nu(z) = \frac{2}{\sqrt{\pi}}e^{-\omega\left[\pi\left(\nu+1/2\right)-z\right]}(2z)^\nu U(\nu+1/2,2\nu+1,-2i\omega z)\qquad (\omega=\pm)
  \end{equation}
we can finally find the CFE
  \begin{equation}
    \label{eq:app.numTools.cfeHankel}
    \frac{dH^\omega_\nu(z)/dz}{H^\omega_\nu(z)} = -\frac{1}{2z}+i\omega+\frac{\omega}{z}\bigk_{m=1}^\infty\left(\frac{\nu^2-(2m-1)^2/4}{2(iz-\omega m)}\right).
  \end{equation}
In our numerical implementation (see next section), we have found that when $|z|<10^{-2}$, convergence is slow. This mirrors the results of \cite{THO1986}.
We thus use the small argument expansions for the Bessel functions (\textit{q.v.} \S \ref{sec:app.Bessel.smallArguments}) to obtain
  \begin{subequations}
  \begin{align}
   \lim_{z\rightarrow0}\frac{dH^\omega_\nu(z)/dz}{H^\omega_\nu(z)}	&= -\frac{\nu}{z}	& (\nu\neq0)	\\
									&= \frac{1}{z}\left[\frac{\pi}{2i\omega}+\gamma+\ln\left(\frac{z}{2}\right)\right]^{-1} & (\nu=0).
  \end{align}
  \end{subequations}

\index{continued fraction expansions|)textbf}

\subsection{Numerical Tests}
We have performed a number of tests to ascertain the performance of our algorithm. 
To test the precision of the algorithm, we have evaluated the CFE for $z\in\{0,10\}$
and $\nu\in\{-100,100\}\in\mathbb{N}$ and compared it to the values obtained via
Amos' library for a range of tolerances. It can be seen that the maximum deviation 
decreases until our set tolerance hits $10^{-12}$ and then plateaus. Because 
convergence of \ref{eq:app.numTools.cfeHankel} is mathematically insured, we 
conclude that Amos's library evaluate the logarithmic derivative up to 
a precision of $10^{-12}$. This is probably due to the propagation 
of errors in the floating point operations, as we use relation
\eqref{eq:app.Bessel.recurrenceDiffBessel}
to evaluate the derivative. 

\begin{figure}
 \centering
 \includegraphics[width=0.7\textwidth]{figs/app-numTools/maxDiff.pdf}
 \caption[Maximum deviation between the CFE and Amos' implementation as a function
	  of the CFE tolerance]%
	 {Maximum deviation between the CFE and Amos' implementation of the Bessel functions
	 as a function of the tolerance of the CFE. This study was performed in the parameter
	 space $z\in\left\{0.1,10\right\}, \nu\in\left\{-100,100\right\}$. We interpret 
	 the plateau in maximum deviation as the error committed by Amos' implementation, i.e.
	 Amos' implementation has a precision of $\sim10^{-10}$ on the evaluation of the logarithmic derivative.}
\end{figure}


\begin{figure}
 \centering
 \begin{subfigure}[t]{0.47\textwidth}
  \centering
  \includegraphics[width=\textwidth]{figs/app-numTools/timesTolerance.pdf}
  \caption{Performance of the CFE implementation as a function of its tolerance.
	   We measured the ratio of the time it takes to compute the logarithmic derivative
	   at $z=0$ for all orders $\nu\in\{-100,100\}$ with the CFE and Amos' implementation. 
	   When the tolerance of the CFE hits $\sim10^{-5.5}$, the CFE is slower than Amos'
	   implementation.}
 \end{subfigure}
 \begin{subfigure}[t]{0.47\textwidth}
  \includegraphics[width=\textwidth]{figs/app-numTools/timesPerformance.pdf}
  \caption{Performance of the CFE as a function of $z$. When approaching
  $z=0$ (from all sides), it takes a higher number of terms for the 
  CFE to converge, resulting in a slower algorithm. However, at $z=10^{-2}$, we 
  use the small argument form, preserving both precision and performance.}
 \end{subfigure}
 \caption[Performance of the CFE compared to Amos' library's.]
	 {Performance of the CFE compared to that of Amos' library. The CFE is somewhat
	 slower, but can achieve better precision.}
\end{figure}


However, it can be seen that Amos' library is somewhat faster, given its
precision, that our CFE evaluation 
even though it requires three Hankel function evaluations. 

%\section{Clebsch-Gordan Coefficients and Wigner Symbols}
\input{backmatter/appWigner.tex}

\input{backmatter/appSphHarmonics.tex}